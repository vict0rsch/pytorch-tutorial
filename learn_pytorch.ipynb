{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vict0rsch/pytorch-tutorial/blob/main/learn_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1fq7azO1_53"
      },
      "source": [
        "# Pytorch Hands-on Tutorial\n",
        "\n",
        "This tutorial has been developed for the IFT 3710/6759  *Projets (avancés) en apprentissage automatique* - *(Advanced) Projects in Machine Learning* course at Université de Montréal, Canada.\n",
        "\n",
        "Course URL: https://alexhernandezgarcia.github.io/teaching/mlprojects/\n",
        "\n",
        "Author: Victor Schmidt (TA) ([Github repository](https://github.com/vict0rsch/pytorch-tutorial))\n",
        "\n",
        "(Python Beginner? [Here are some recommendations](https://www.notion.so/vsch/Python-recommendations-957ee124321a41fdbaf258cc7dbbfdcb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dofkJqR41_59"
      },
      "source": [
        "## Notebook Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSpCuQ7K9OAG"
      },
      "source": [
        "0. Utils & Imports\n",
        "1. Linear Regression with Pytorch\n",
        "2. Data sets & Data loading\n",
        "3. Real-world training scenario in Computer Vision\n",
        "4. Your turn to play around and improve accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46it9awf1_5-"
      },
      "source": [
        "The goal of this Notebook is to get you to run things and play around. Little maths are covered here so the basics of Neural Networks and Automatic Differentiation are required for in-depth comprehension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDWqZXEk1_5-"
      },
      "source": [
        "Official resources:\n",
        "* [Deep Learning with PyTorch: a 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "* [PyTorch documentation](https://pytorch.org/docs/stable/index.html)\n",
        "\n",
        "You'll find more pointers at the end of this tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guIcdc6U1_5_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSE6Vi_51_5_"
      },
      "source": [
        "## 0. Imports & Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure the Notebook is \"Connected\" with a GPU enabled. Check in the top right."
      ],
      "metadata": {
        "id": "7CQHN6Q4_sjD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3f-94908PPC"
      },
      "source": [
        "Let's install a few libraries, nothing fancy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMmjvhmG2EVz"
      },
      "outputs": [],
      "source": [
        "! pip install torch torchvision matplotlib numpy scikit-image torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Curquz6g8XZF"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPamDoX51_6A"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io as io\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDh0uQag8bso"
      },
      "source": [
        "**Utility functions**: you need not read through this code to understand what will happen in this tutorial.\n",
        "\n",
        "You **do** however need to *execute* them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCXJf74W81Kb"
      },
      "outputs": [],
      "source": [
        "# Plot the time-series of errors and accuracies\n",
        "# for validation and train splits\n",
        "def plot_error_and_accuracy(errors, accuracies, title=\"\"):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        errors (dict): dictionary of errors over epochs {\"train\": [], \"val\": []}\n",
        "        accuracies (dict): similar, for accuracy\n",
        "        title (optional, str): Plot title. Defaults to \"\".\n",
        "    \"\"\"\n",
        "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    x = range(len(errors[\"train\"]))\n",
        "    ax1.plot(x, errors[\"train\"], label=\"Training\")\n",
        "    ax1.plot(x, errors[\"val\"], label=\"Validation\")\n",
        "    ax1.title.set_text(\"Cross-entropy error\")\n",
        "\n",
        "    ax2.plot(x, accuracies[\"train\"], label=\"Training\")\n",
        "    ax2.plot(x, accuracies[\"val\"], label=\"Validation\")\n",
        "    ax2.title.set_text(\"Prediction Accuracy\")\n",
        "\n",
        "    if title:\n",
        "        plt.suptitle(title)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j68moFUy86W6"
      },
      "outputs": [],
      "source": [
        "# GPUMonitor class to monitor GPU utilization in the background\n",
        "\n",
        "import subprocess\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "def gpu_util():\n",
        "    format = \"csv,nounits,noheader\"\n",
        "    queries = [\"utilization.gpu\", \"memory.used\", \"memory.free\", \"utilization.memory\"]\n",
        "    gpu_query = \",\".join(queries)\n",
        "    gpu_ids = 0\n",
        "\n",
        "    result = subprocess.run(\n",
        "        [\n",
        "            shutil.which(\"nvidia-smi\"),\n",
        "            f\"--query-gpu={gpu_query}\",\n",
        "            f\"--format={format}\",\n",
        "            f\"--id={gpu_ids}\",\n",
        "        ],\n",
        "        encoding=\"utf-8\",\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        check=True,\n",
        "    )\n",
        "    stats = [\n",
        "        [float(x) for x in s.split(\", \")]\n",
        "        for s in result.stdout.strip().split(os.linesep)\n",
        "    ][0]\n",
        "    utilization = {}\n",
        "    for k, q in enumerate(queries):\n",
        "        utilization[q] = stats[k]\n",
        "    return utilization\n",
        "\n",
        "\n",
        "from threading import Thread\n",
        "from time import sleep, time\n",
        "\n",
        "\n",
        "class GPUMonitor:\n",
        "    def __init__(self, timeout=1):\n",
        "        self.timeout = timeout\n",
        "\n",
        "        self._thread = Thread(target=self._monitor, daemon=True)\n",
        "        self.utilization = None\n",
        "        self.done = False\n",
        "        self.start_time = self.stop_time = None\n",
        "\n",
        "    def start(self):\n",
        "        self._thread.start()\n",
        "        self.start_time = time()\n",
        "        return self\n",
        "\n",
        "    def _monitor(self):\n",
        "        while True:\n",
        "            if self.done:\n",
        "                break\n",
        "            utilization = gpu_util()\n",
        "            if self.utilization is None:\n",
        "                self.utilization = {k: [] for k in utilization}\n",
        "            for k, v in utilization.items():\n",
        "                self.utilization[k].append(v)\n",
        "            sleep(self.timeout)\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start()\n",
        "\n",
        "    def stop(self):\n",
        "        self.stop_time = time()\n",
        "        self.done = True\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, tb):\n",
        "        # handle exceptions with those variables ^\n",
        "        self.stop()\n",
        "\n",
        "    def plot_all(self, figsize=(10, 10)):\n",
        "        f, axs = plt.subplots(2, 2, figsize=figsize)\n",
        "        for i in range(2):\n",
        "            for j in range(2):\n",
        "                ax = axs[i][j]\n",
        "                k = list(self.utilization.keys())[i * 2 + j]\n",
        "                data = self.utilization[k]\n",
        "                ax.plot(range(len(data)), data)\n",
        "                ax.title.set_text(k)\n",
        "        plt.suptitle(\"GPU monitoring\")\n",
        "\n",
        "    def plot(self, k):\n",
        "        assert k in self.utilization, f\"Unknown metric {k}\"\n",
        "        data = self.utilization[k]\n",
        "        plt.plot(range(len(data)), data)\n",
        "        plt.title(\"GPU monitoring: \" + k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhrquG-lJTYX"
      },
      "outputs": [],
      "source": [
        "# Download a \"real world\" dataset of 126MB\n",
        "# in Colab's local disk\n",
        "def download_data():\n",
        "    from pathlib import Path\n",
        "    from urllib.request import urlopen\n",
        "    from zipfile import ZipFile\n",
        "\n",
        "    data_path = Path(\"./tutorial-data\")\n",
        "    data_path.mkdir(exist_ok=True)\n",
        "    zip_file = data_path / \"summer2winter_yosemite.zip\"\n",
        "    unzipped = data_path / \"summer2winter_yosemite\"\n",
        "\n",
        "    if zip_file.exists() or unzipped.exists():\n",
        "        print(\"Data already exists. Downloading skipped.\")\n",
        "    else:\n",
        "        url = \"https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/summer2winter_yosemite.zip\"\n",
        "        print(\"Downloading data... \", end=\"\", flush=True)\n",
        "        with urlopen(url) as response, open(zip_file, \"wb\") as out_file:\n",
        "            data = response.read()\n",
        "            out_file.write(data)\n",
        "        print(\"Done.\")\n",
        "\n",
        "        print(\"Unzipping dataset... \", end=\"\", flush=True)\n",
        "        with ZipFile(zip_file, \"r\") as zip:\n",
        "            zip.extractall(data_path)\n",
        "        print(\"Done.\")\n",
        "\n",
        "    print(\"Available data:\")\n",
        "    for d in unzipped.iterdir():\n",
        "        if d.is_dir():\n",
        "            print(f\"  {d.name} ({len(list(d.glob('*.jpg')))} images)\")\n",
        "\n",
        "    return unzipped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_R6-SX1ReHF"
      },
      "outputs": [],
      "source": [
        "def correct(predictions, labels):\n",
        "    \"\"\"\n",
        "    Counts the number of correct predictions\n",
        "\n",
        "    Args:\n",
        "        predictions (torch.Tensor): array of model predictions. Can be either\n",
        "            1D (batch of class indices) or 2D (batch of prediction vectors)\n",
        "        labels (torch.Tensor): array of ground truth target labels (1D)\n",
        "    \"\"\"\n",
        "    if predictions.ndim > labels.ndim:\n",
        "        predictions = predictions.max(1).indices\n",
        "\n",
        "    correct_predictions = predictions.cpu() == labels.cpu()\n",
        "    correct_count = correct_predictions.float().sum()\n",
        "    return correct_count.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH5jGc8BvxC9"
      },
      "outputs": [],
      "source": [
        "# From\n",
        "# https://discuss.pytorch.org/t/reproducibility-with-all-the-bells-and-whistles/81097\n",
        "\n",
        "\n",
        "def seed_all(seed):\n",
        "    \"\"\"\n",
        "    Seed Python, Numpy and Pytorch for reproducibility.\n",
        "    \"\"\"\n",
        "\n",
        "    if not seed:\n",
        "        seed = 10\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # np.random.seed(seed)\n",
        "    rng = np.random.default_rng(seed=seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    return rng\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    \"\"\"\n",
        "    Seed data loader workers\n",
        "    \"\"\"\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "rng = seed_all(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFv-wa491_6C"
      },
      "source": [
        "## 1. Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVdT4RKX9RWN"
      },
      "source": [
        "### 1.1 A toy dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq1VIyWb1_6C"
      },
      "source": [
        "The data is obtained from a linear model (true distribution)\n",
        "$$\n",
        "x \\mapsto y:=Ax + b\n",
        "$$\n",
        "with $x\\in\\mathbb R^{input\\_dim}$ and $y\\in\\mathbb R^{output\\_dim}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF3Dq-WT1_6D"
      },
      "outputs": [],
      "source": [
        "input_dim = 1\n",
        "output_dim = 1\n",
        "\n",
        "A = 2 * rng.random((output_dim, input_dim)) - 1\n",
        "b = 2 * rng.random((output_dim)) - 1\n",
        "\n",
        "true_model = lambda x: A @ x + b\n",
        "\n",
        "print(\n",
        "    f\"A: {A[0, 0]:.4f}, b:{b[0]:.4f}, x: {2} => A @ x + b: {true_model(np.array([2]))[0]:.4f}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKok3cNm1_6F"
      },
      "source": [
        "We simulate a data set by randomly sampling noisy observations from the true distribution\n",
        "\\begin{align*}\n",
        "&x_i \\sim U([-1, 1])\\\\\n",
        "&y_i = A x_i + b + \\nu_i\n",
        "\\end{align*}\n",
        "\n",
        "And then select 1000 samples to train on, 500 to validate and 500 to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acY54opE1_6F"
      },
      "outputs": [],
      "source": [
        "n_samples = 2000\n",
        "n_train = 1000\n",
        "noise_level = 0.03\n",
        "\n",
        "# Generate a random set of n_train samples\n",
        "X = rng.random((n_samples, input_dim))\n",
        "Y = np.array([true_model(x) for x in X])\n",
        "\n",
        "# Add some noise\n",
        "Y += noise_level * rng.standard_normal(size=Y.shape)\n",
        "\n",
        "# Train/Val/Test splits\n",
        "X_train = X[:n_train]\n",
        "y_train = Y[:n_train]\n",
        "\n",
        "X_val = X[n_train : n_train + 500]\n",
        "y_val = Y[n_train : n_train + 500]\n",
        "\n",
        "X_test = X[n_train + 500 :]\n",
        "y_test = Y[n_train + 500 :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBVW4bsp1_6G"
      },
      "outputs": [],
      "source": [
        "if input_dim == output_dim == 1:\n",
        "    fig = plt.figure()\n",
        "    fig.clf()\n",
        "    ax = fig.gca()\n",
        "    ax.plot(X_train, y_train, \".\")\n",
        "    ax.grid(True)\n",
        "    ax.set_xlabel(\"X_train\")\n",
        "    ax.set_ylabel(\"y_train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guu5ZEUF1_6H"
      },
      "source": [
        "**Task**: fit a model (here a linear model) to recover the true underlying parameters of the data distribution, *i.e.* $A$ and $b$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTipiO0haGzc"
      },
      "source": [
        "### 1.2 Why Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GjBq2KKaMf2"
      },
      "source": [
        "In a nutshell Pytorch is a computational framework allowing for all kinds of mathematical operations with a focus on 2 particular features that differentiate it from your standard Numpy library:\n",
        "\n",
        "1. Automatic differentiation\n",
        "2. GPU acceleration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKkKSevnyv4h"
      },
      "source": [
        "\n",
        "#### 1.2.1 Autodiff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfT-innLyxk9"
      },
      "source": [
        "Recall\n",
        "\n",
        "$$\n",
        "(v∘u)'(x) = u'(x) ⋅ (v'∘ u) (x) = u'(x) \\cdot v'(u(x))\n",
        "$$\n",
        "\n",
        "Let\n",
        "\n",
        "$$\n",
        "f: x \\rightarrow \\log(x^2)\n",
        "$$\n",
        "If we want to compute its gradient with respect with some input $x_0$:\n",
        "$$\n",
        "\\frac{∂\\log(x^2)}{\\partial x}\\rvert_{x=x_0} = \\frac{\\partial x^2}{\\partial x}\\rvert_{x=x_0} \\cdot \\frac{\\partial \\log(y)}{\\partial y} \\rvert_{y=x_0^2} = 2x_0 \\cdot \\frac{1}{x_0^2} = \\frac{2}{x_0}\n",
        "$$\n",
        "Notice we need not know the derivative of the final complex function, rather that of its individual blocks. This is at the core of Pytorch's `AutoGrad` engine, which automatically computes those intermediate derivatives, whatever the form of the final function and however complex it is. The *only requirement* is that every operation in your function, from the input to the output, is differentiable.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTudmJTXhb-a"
      },
      "source": [
        "#### 1.2.2 GPU acceleration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxBMnsHkyqlo"
      },
      "source": [
        "\n",
        "In short, at the core of Deep Learning is a bunch of matrix multiplications. The great thing about those is that output values are *independent*: you need not know the value of any $c_{i,j}$ to compute $c_{k,l}$. \n",
        "\n",
        "Say we want to compute $C = A\\times B$:\n",
        "\n",
        "$$\n",
        "c_{i,j} = A_{i:}^{\\top}B_{:j}\n",
        "$$\n",
        "\n",
        "Think of GPUs as thousands of mini-CPUs working in parallel, each of them can compute a different $c_{ij}$ independently of others and in parallel. This is obviously also true for more generic tenor multiplications or element-wise operations.\n",
        "\n",
        "As a consequence, training neural networks on GPUs can be orders-of-magnitude faster than on CPUs, and Pytorch provides very easy functions to do all your calculations seamlessly on GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAMn8waR1_6I"
      },
      "source": [
        "### 1.3 Pytorch Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk7op-pr1_6I"
      },
      "source": [
        "In `torch` a model inherits from the class `torch.nn.Module` whose only requirement is to have a `.forward()` method implemented.\n",
        "\n",
        "In this section we will create a linear model, which takes $x$ as input and produces $y$:\n",
        "\n",
        "```python\n",
        "y = model(x)\n",
        "```\n",
        "\n",
        "To implement the model, we will create our own Python `class` describing the expected behavior of such a model: \n",
        "1. what is its architecture? (`__init__(...)`)\n",
        "2. how does it process inputs it receives? (`forward(...)`)\n",
        "\n",
        "👋 Your **first exercise** is to fill in the `forward()` method in the `LinearModel` class ⬇️"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMfV-up-1_6I"
      },
      "outputs": [],
      "source": [
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, in_dim=1, out_dim=1):\n",
        "        \"\"\"\n",
        "        Creates a linear model to predict vectors of size `out_dim`\n",
        "        from vectors of size `in_dim`:\n",
        "\n",
        "            y = W @ x + b\n",
        "            <=>\n",
        "            y = x @ W^T + b\n",
        "\n",
        "        Args:\n",
        "            in_dim (int): the size of the input vectors\n",
        "            out_dim (int): the size of the output vectors\n",
        "        \"\"\"\n",
        "        # initialization of the parent class\n",
        "        super().__init__()\n",
        "        # create a weight matrix. we start with random numbers\n",
        "        # and they will be adjusted over the course of training\n",
        "        self.weight = nn.Parameter(torch.randn(out_dim, in_dim))\n",
        "        # create a bias vector.\n",
        "        self.bias = nn.Parameter(torch.randn(out_dim))\n",
        "        # initialize the weight's & bias's values\n",
        "        self.init()\n",
        "\n",
        "    # def __call__(self, *args, **kwargs):\n",
        "    #     # Under the hood, PyTorch implements this __call__() method\n",
        "    #     # so that ``model(x)`` is equivalent to ``model.forward(x)``\n",
        "    #     # \n",
        "    #     # This is FYI, nothing to do here!   \n",
        "    #     return self.forward(*args, **kwargs)\n",
        "\n",
        "    def init(self):\n",
        "        \"\"\"\n",
        "        Initialize weights and biases according to a normal distribution.\n",
        "        Look into `nn.init` for more options\n",
        "        https://pytorch.org/docs/stable/nn.init.html\n",
        "        \"\"\"\n",
        "        nn.init.normal_(self.weight, mean=0, std=0.1)\n",
        "        nn.init.constant_(self.bias, 0)\n",
        "\n",
        "    # TODO ⬇️\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward = how to produce the output(s) of this model given some input(s)\n",
        "\n",
        "        make sure that:\n",
        "            * data types are compatible (e.g. float32 (\"float\") vs. float64 (\"double\"))\n",
        "            * shapes are compatible (usually the first dimension is the batch size)\n",
        "            * devices are compatible (e.g. CPU vs. GPU) (see later)\n",
        "\n",
        "        Args:\n",
        "            x (torch.tensor): input tensor with dimensions [batch_size, in_dim]\n",
        "\n",
        "        Returns:\n",
        "            torch.tensor: output tensor with dimensions [batch_size, out_dim]\n",
        "        \"\"\"\n",
        "\n",
        "        assert x.shape[-1] == self.weight.shape[-1]\n",
        "        y = 0\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have implemented the `forward()` method above, we'll see how we could have done differently and check that it's all equivalent 🎉"
      ],
      "metadata": {
        "id": "FqGYtyxnDLtu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmVM06-i1_6J"
      },
      "outputs": [],
      "source": [
        "# 1️⃣\n",
        "# create an instance of our custom model class.\n",
        "model = LinearModel()\n",
        "\n",
        "# 2️⃣\n",
        "# as you can imagine, Pytorch has this already implemented.\n",
        "# Let's compare our implementation with theirs.\n",
        "simple_model = torch.nn.Linear(1, 1)\n",
        "#\n",
        "# make sure the nn.Linear model starts off just like ours\n",
        "W = model.weight.data\n",
        "b = model.bias.data\n",
        "simple_model.weight.data = W\n",
        "simple_model.bias.data = b\n",
        "\n",
        "# select a sample x and its associated target y_target\n",
        "x = torch.tensor(X_train[:1], dtype=torch.float32)  # 👋 Q: why [:1] and not [0]?\n",
        "y_target = torch.tensor(y_train[:1], dtype=torch.float32)\n",
        "\n",
        "# 1️⃣ predict y value from sample x\n",
        "y = model(x)\n",
        "# 2️⃣ compare with nn.Linear prediction\n",
        "y_simple = simple_model(x)\n",
        "# 3️⃣ compare with \"manual\" calculations\n",
        "y_manual = x @ W.T + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_i_QJaf1_6J"
      },
      "outputs": [],
      "source": [
        "# a bunch of prints to compare all of the above^\n",
        "print(f\"Sample input x       : {x.item():.5f}\")\n",
        "print(f\"Model weight         : {model.weight.data}\")\n",
        "print(f\"Model bias           : {model.bias.data}\")\n",
        "print(f\"\\nPredictions:\")\n",
        "print(f\"  Model Forward        : {y.item():.5f}\")\n",
        "print(f\"  Simple Model Forward : {y_simple.item():.5f}\")\n",
        "print(f\"  Manual mat-mul       : {y_manual.item():.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wondering what `.item()` means? it turns a single-valued `torch.Tensor` into a Python scalar:"
      ],
      "metadata": {
        "id": "Y2BJyVAmFZHM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58Th0USf1_6K"
      },
      "outputs": [],
      "source": [
        "# FYI: tensor.item(): get a native Python scalar\n",
        "print(type(x))\n",
        "print(type(x.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7SW-FDa1_6K"
      },
      "source": [
        "### 1.4 Optimization: learning the model's weights\n",
        "\n",
        "In this section we'll see how to actually train the model to fit the data.\n",
        "\n",
        "TL;DR => 1. compute loss 2. update weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBdEdxW01_6L"
      },
      "source": [
        "#### 1.4.1 Loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGVuFwv9ANln"
      },
      "source": [
        "\n",
        "We want to compute the regression error made by the predictor as:\n",
        "\n",
        "$$\n",
        "L(y, y') = \\|y-y'\\|_2^2\n",
        "$$\n",
        "\n",
        "* for scalars:\n",
        "\n",
        "    $$\n",
        "    L(y, y') = (y_i - y_i')^2\n",
        "    $$\n",
        "\n",
        "* for vectors\n",
        "\n",
        "    $$\n",
        "    L(y, y') = \\sum_{d=0}^{out\\\\_dim-1}(y^{d} - y'^{d})^2\n",
        "    $$\n",
        "\n",
        "* for batches (average error)\n",
        "    $$ \n",
        "    L(y, y') = \\frac{1}{N} \\sum_{i=0}^{N-1} \\sum_{d=0}^{out\\\\_dim-1}(y^{d}_i - y'^{d}_i)^2\n",
        "    $$ \n",
        "\n",
        "This function is called the MSE (Mean Squared Error)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👋 Your **second exercise** is to implement the MSE loss in `custom_loss()` ⬇️"
      ],
      "metadata": {
        "id": "EdVg0r4pF2xy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzehZTKF1_6L"
      },
      "outputs": [],
      "source": [
        "def custom_loss(prediction, ground_truth):\n",
        "    \"\"\"\n",
        "    Compute the mean squared error between two tensors.\n",
        "\n",
        "    Args:\n",
        "        prediction (torch.tensor): predicted values by some models\n",
        "        ground_truth (torch.tensor): ground truth values which should have been predicted\n",
        "\n",
        "    Returns:\n",
        "        float: mean squared error\n",
        "    \"\"\"\n",
        "    # make sure shapes are compatible\n",
        "    assert prediction.shape == ground_truth.shape\n",
        "    error = 0  # TODO\n",
        "    return error\n",
        "\n",
        "\n",
        "custom_error = custom_loss(y, y_target)\n",
        "\n",
        "# compare with built-in implementation\n",
        "torch_loss = torch.nn.MSELoss()\n",
        "torch_error = torch_loss(y, y_target)\n",
        "\n",
        "print(custom_error)\n",
        "print(torch_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC5dD_rZ1_6L"
      },
      "source": [
        "There are many other loss functions in PyTorch, see https://pytorch.org/docs/stable/nn.html#loss-functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QSFCn0l1_6M"
      },
      "source": [
        "#### 1.4.2 Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btfLoL8RAtPT"
      },
      "source": [
        "\n",
        "Once the model has made a prediction and its error has been measured with the loss function, we need to update its parameters in the direction of smaller loss.\n",
        "\n",
        "To that end, PyTorch implements a wide variety of *optimizers*: they take in the model's parameters, a learning rate (and some other stuff sometimes) and will update the parameters based on the loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2W2dp8w1_6M"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "# also try torch.optim.Adam\n",
        "# see https://pytorch.org/docs/stable/optim.html#algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTj5MsOF1_6M"
      },
      "source": [
        "What now? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkg5x7331_6M"
      },
      "source": [
        "We need to compute the **gradients** so that the optimizer can update the parameters!\n",
        "\n",
        "For instance the update rule for *gradient descent*:\n",
        "$$\n",
        "w' \\leftarrow w -\\alpha \\nabla_\\theta L(f_\\theta(x), y)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwY1hvk11_6M"
      },
      "outputs": [],
      "source": [
        "s = \"Parameter value: {:.5f} | Parameter gradient: {}\"\n",
        "# recall: error is mse(prediction, ground_truth_target)\n",
        "for p in model.parameters():\n",
        "    print(s.format(p.data.item(), p.grad))\n",
        "print(\n",
        "    \"\\nSo far, no gradient is available, we need to call .backward() on the loss\\n\"\n",
        "    + \"to perform the backward pass and compute the gradient of the loss\\n\"\n",
        "    + \"with respect to each parameter\\n\"\n",
        ")\n",
        "\n",
        "custom_error.backward()\n",
        "\n",
        "for p in model.parameters():\n",
        "    print(s.format(p.data.item(), p.grad.item()))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that gradients have been computed using `.backward()` we will verify using the parameters' `.grad` attributes that the manual SGD update rule is what is in fact done by the optimizer's `.step()` method."
      ],
      "metadata": {
        "id": "hYqUgzvSHNzP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh3pYPuj1_6N"
      },
      "outputs": [],
      "source": [
        "s = \"Parameter value: {:.5f} | Parameter gradient: {:.5f} | Updated parameter value should be: {:.5f}\"\n",
        "\n",
        "for p in model.parameters():\n",
        "    print(\n",
        "        s.format(p.data.item(), p.grad.item(), (p - learning_rate * p.grad).data.item())\n",
        "    )\n",
        "print()\n",
        "\n",
        "print(\n",
        "    \"Let's perform an 'optimizer step' to update weights according to the\\n\"\n",
        "    + \"SGD optimization strategy and check that resulting values correspond\\n\"\n",
        "    + \"to the ones we expect (^)\\n\"\n",
        ")\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "for p in model.parameters():\n",
        "    print(\"Parameter value: {:.5f} \".format(p.data.item()))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjUy99ytll1C"
      },
      "source": [
        "#### 1.4.3 Learning rate scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icj_wu2Ilr3h"
      },
      "source": [
        "In many practical cases, it helps to adjust your learning rate during training. For instance, start larger early on to make bigger optimization steps, but reduce over the course of training to make smaller steps as you (hopefully) approach a (local?) minimum.\n",
        "\n",
        "Pytorch uses learning rate \"schedulers\" to do so:\n",
        "\n",
        "```python\n",
        "for e in range(epochs):\n",
        "    for batch in train_loader:\n",
        "        ...\n",
        "        optimizer.step()\n",
        "    # update the learning rate at the end of an epoch\n",
        "    scheduler.step()\n",
        "```\n",
        "\n",
        "Reference: https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following piece of code plots how a learning rate scheduler changes the actual learning rate in the optimizer's `step()` over the course of training."
      ],
      "metadata": {
        "id": "O-mCqPthIBfk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wzm1GkKln8wD"
      },
      "outputs": [],
      "source": [
        "model = LinearModel(1, 1)\n",
        "optimizer1 = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "optimizer2 = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "optimizer3 = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Decay LR by a factor of 0.5 every 20 epochs (lr is halved every 20 epochs)\n",
        "step_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer1, step_size=20, gamma=0.5)\n",
        "# Grow the learning rate from 0.05 * lr to lr in 100 epochs (learning rate warmup)\n",
        "lin_lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
        "    optimizer2, start_factor=1, end_factor=0.25, total_iters=100\n",
        ")\n",
        "# Multiply the learning rate by 0.9 at each epoch\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer3, 0.95)\n",
        "\n",
        "lrs = {\"step\": [], \"lin\": [], \"exp\": []}\n",
        "for epoch in range(200):\n",
        "    lrs[\"step\"].append(optimizer1.param_groups[0][\"lr\"])\n",
        "    lrs[\"lin\"].append(optimizer2.param_groups[0][\"lr\"])\n",
        "    lrs[\"exp\"].append(optimizer3.param_groups[0][\"lr\"])\n",
        "\n",
        "    step_lr_scheduler.step()\n",
        "    lin_lr_scheduler.step()\n",
        "    # you are free to control that descent yourself too!\n",
        "    if optimizer3.param_groups[0][\"lr\"] > 1e-3:\n",
        "        exp_lr_scheduler.step()\n",
        "\n",
        "for name, data in lrs.items():\n",
        "    plt.plot(range(len(data)), data, label=name)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnROs_Bl1_6N"
      },
      "source": [
        "#### 1.4.4 Overall single optimization step"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting it all together here's what a full sigle optimization step looks like:\n",
        "\n",
        "1. define your data, batch size, model, loss, optimizer etc.\n",
        "2. compute your model's prediction from `x`\n",
        "3. compute its error with respect to the ground-truth with your `loss`\n",
        "4. compute the gradient of the loss with respect to each paramter with `.backward()`\n",
        "5. adjust weights accordingly with `optimizer.step()`\n",
        "6. if need be, adjust the current learning rate with `scheduler.step()`\n",
        "7. the new error (at least on the same input) is now lower!"
      ],
      "metadata": {
        "id": "dXTNEkeaIsAJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jPdkbyB1_6N"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "perm = rng.permutation(len(X_train))\n",
        "\n",
        "x_batch = X_train[perm[:batch_size]]\n",
        "y_batch = y_train[perm[:batch_size]]\n",
        "\n",
        "x = torch.tensor(x_batch, dtype=torch.float32)\n",
        "y = torch.tensor(y_batch, dtype=torch.float32)\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "loss = torch.nn.MSELoss()\n",
        "\n",
        "y_pred = model(x)\n",
        "error = loss(y_pred, y)\n",
        "print(f\"Error                                           : {error.item():.5f}\")\n",
        "error.backward()\n",
        "optimizer.step()\n",
        "# if you have a scheduler and it is the end of an epoch:\n",
        "# scheduler.step()\n",
        "\n",
        "y_pred = model(x)\n",
        "new_error = loss(y_pred, y)\n",
        "print(f\"New error on the same batch, after SGD update   : {new_error.item():.5f}\")\n",
        "print(f\"New loss value is smaller than the previous one : {(new_error < error).item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHQLoAgD1_6N"
      },
      "source": [
        "### 1.5 Full training procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-0JbNIs1_6N"
      },
      "outputs": [],
      "source": [
        "# define hyper-parameters for the training procedure\n",
        "epochs = 250\n",
        "batch_size = 32\n",
        "learning_rate = 0.01\n",
        "\n",
        "# pre-calculate number of batches in the data sets\n",
        "n_train_batches = len(X_train) // batch_size\n",
        "n_val_batches = len(X_val) // batch_size\n",
        "\n",
        "# initialize model\n",
        "model = LinearModel(1, 1)\n",
        "# create optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "# create loss function\n",
        "loss = torch.nn.MSELoss()\n",
        "\n",
        "# Store epoch-wise MSEs\n",
        "errors = {\"train\": [], \"val\": []}\n",
        "\n",
        "# -----------------------------------\n",
        "# --  Start of training procedure  --\n",
        "# -----------------------------------\n",
        "for e in range(epochs):\n",
        "\n",
        "    # randomly order training samples at each epoch\n",
        "    # so they are not always seen together\n",
        "    perm = rng.permutation(len(X_train))\n",
        "\n",
        "    # store batch-wise MSE\n",
        "    train_errors = []\n",
        "\n",
        "    # ----------------------\n",
        "    # --  Training epoch  --\n",
        "    # ----------------------\n",
        "\n",
        "    for i in range(n_train_batches):\n",
        "\n",
        "        # select samples and their associated target values\n",
        "        x_batch = X_train[perm[i * batch_size : (i + 1) * batch_size]]\n",
        "        y_batch = y_train[perm[i * batch_size : (i + 1) * batch_size]]\n",
        "\n",
        "        # transform them into torch tensors\n",
        "        x = torch.tensor(x_batch, dtype=torch.float32)\n",
        "        y = torch.tensor(y_batch, dtype=torch.float32)\n",
        "\n",
        "        # make sure all gradients are empty\n",
        "        optimizer.zero_grad()\n",
        "        # compute prediction\n",
        "        y_pred = model(x)\n",
        "        # compute error\n",
        "        error = loss(y_pred, y)\n",
        "        # perform backward pass\n",
        "        error.backward()\n",
        "        # update model weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # store this batch's MSE\n",
        "        train_errors.append(error.item())\n",
        "\n",
        "    # if you have a scheduler: scheduler.step()\n",
        "\n",
        "    # ------------------------\n",
        "    # --  Validation epoch  --\n",
        "    # ------------------------\n",
        "\n",
        "    val_errors = []\n",
        "    # temporarily de-activate gradients to speed-up\n",
        "    # computations as they will not be required in validation\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_val_batches):\n",
        "            # same as training except we don't call .backward() and don't\n",
        "            # update model weights\n",
        "            x_batch = X_val[i * batch_size : (i + 1) * batch_size]\n",
        "            y_batch = y_val[i * batch_size : (i + 1) * batch_size]\n",
        "\n",
        "            x = torch.tensor(x_batch, dtype=torch.float32)\n",
        "            y = torch.tensor(y_batch, dtype=torch.float32)\n",
        "\n",
        "            y_pred = model(x)\n",
        "            error = loss(y_pred, y)\n",
        "            val_errors.append(error.item())\n",
        "\n",
        "    # store average error and some prints\n",
        "\n",
        "    train_error = np.mean(train_errors)\n",
        "    val_error = np.mean(val_errors)\n",
        "\n",
        "    errors[\"train\"].append(train_error)\n",
        "    errors[\"val\"].append(val_error)\n",
        "\n",
        "    print(\n",
        "        f\"\\rEpoch {e + 1}/{epochs} | Train loss: {train_error:.5f} | Val loss: {val_error:.5f}\",\n",
        "        end=\"\",\n",
        "    )\n",
        "\n",
        "    # --------------------\n",
        "    # --  End of epoch  --\n",
        "    # --------------------\n",
        "\n",
        "# ---------------------------------\n",
        "# --  End of training procedure  --\n",
        "# ---------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ummEr7ur1_6O"
      },
      "outputs": [],
      "source": [
        "# Plot train and val losses as functions of epoch number\n",
        "plt.figure()\n",
        "plt.plot(errors[\"train\"], label=\"train\")\n",
        "plt.plot(errors[\"val\"], label=\"val\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.yscale(\"log\")\n",
        "\n",
        "# Plot the training and validation data\n",
        "# alongside the learned model\n",
        "fig = plt.figure()\n",
        "fig.clf()\n",
        "ax = fig.gca()\n",
        "ax.plot(X_train, y_train, \"+\", label=\"Train\")\n",
        "ax.plot(X_val, y_val, \"x\", label=\"Val\")\n",
        "ax.grid(True)\n",
        "ax.set_xlabel(\"X\")\n",
        "ax.set_ylabel(\"y\")\n",
        "plt.plot(\n",
        "    np.linspace(0, 1, 100),\n",
        "    [\n",
        "        model(torch.tensor([x], dtype=torch.float32)).item()\n",
        "        for x in np.linspace(0, 1, 100)\n",
        "    ],\n",
        "    \"g-\",\n",
        "    label=\"Model\",\n",
        ")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"True data parameters   -> slope: {A[0, 0]:.5f}, bias: {b[0]:.5f}\")\n",
        "print(\n",
        "    f\"SGD-trained parameters -> slope: {model.weight.item():.5f}, bias: {model.bias.item():.5f}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWlS6nI41_6O"
      },
      "source": [
        "## 2. Data sets and data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgskwFCw1_6O"
      },
      "source": [
        "In the previous section, we use the raw data (`X_train[...]`) directly. But in many cases, this is not actually what we do, for instance:\n",
        "\n",
        "* datasets often don't fit in memory so we need to read the data from the disk when we need it, *i.e.* for each batch\n",
        "* pre-processings can be heavy (think: image transformations such as resizing, color jittering etc.)\n",
        "\n",
        "If those steps are slow, then the whole procedure is slowed down not by the training itself, but because the actual training parts of your code have to wait for the data-loading parts.\n",
        "\n",
        "To that end, `torch` introduces 2 concepts:\n",
        "\n",
        "* a `Dataset` is an object which define how 1 *single* sample should be processed. In other words, what does it mean for your training code to ask for sample `i`?\n",
        "* a `Dataloader` is another object which requires a `Dataset` and will take care of (mostly) 2 things for you: 1/ batching dataset samples together 2/ parallelization with background workers (other processes) so that the main training process does not wait.\n",
        "\n",
        "Ideally, you have enough workers such that your main code `for batch in loader` never waits for the data to be processed, since as soon as a batch is produced, another worker is ready with its own batch and the emptied worker goes back to loading and processing the data in the mean time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXv3nj4S1_6P"
      },
      "source": [
        "### 2.1 Data sets\n",
        "\n",
        "A `Dataset` inherits from the `torch.utils.data.Dataset` class, and (in addition to the regular `__init__`) defines at least 2 methods:\n",
        "\n",
        "* `__len__(self):` which should return an `int` describing the length of the dataset, *i.e.* the number of samples it contains\n",
        "* `__getitem__(self, i)` which can return \"sample `i`\" in any form that you want. Typically this is a `torch.Tensor`, or a `tuple` of tensors, or a `dict` of tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6rNhBCg1_6P"
      },
      "outputs": [],
      "source": [
        "# let's download some data\n",
        "data_path = download_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH7vP7XZJeRg"
      },
      "source": [
        "The data we just downloaded contains 2740 `256x256` images of Yosemite National Park, California, divided into train and test sets, and 2 categories: summer pictures or winter pictures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lprhUuUO1_6P"
      },
      "outputs": [],
      "source": [
        "# let's look at sample from both classes\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax1.imshow(plt.imread(data_path / \"trainA\" / \"2010-09-11 03:15:45.jpg\"))\n",
        "ax2.imshow(plt.imread(data_path / \"trainB\" / \"2008-01-19 07:55:07.jpg\"))\n",
        "_ = ax1.axis(\"off\")\n",
        "_ = ax2.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmmAmdIn1_6P"
      },
      "outputs": [],
      "source": [
        "# check the shape of each sample\n",
        "shapes = {\"A\": set(), \"B\": set()}\n",
        "\n",
        "for label in shapes:\n",
        "    for im_path in (data_path / f\"train{label}\").glob(\"*.jpg\"):\n",
        "        im = plt.imread(im_path)\n",
        "        shapes[label].add(tuple(im.shape))\n",
        "\n",
        "print(shapes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uTLUMMMJ9GU"
      },
      "source": [
        "Now that we know what data we have, let's create a Pytorch dataset to produce actual data arrays from those image files, along with their associated label, *i.e.* \"winter\" or \"summer\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZCCMhAz1_6Q"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, base_path, train=True, transform=None):\n",
        "        # where is the data\n",
        "        self.base_path = Path(base_path)\n",
        "        # train or validation?\n",
        "        self.train = train\n",
        "        # function to transform an image after it has been loaded into an array\n",
        "        self.transform = transform\n",
        "        # list of image paths\n",
        "        self.images = []\n",
        "\n",
        "        # let's find all relevant image paths\n",
        "        self.discover_images()\n",
        "\n",
        "    def discover_images(self):\n",
        "        # fill the self.images list depending on whether this dataset should produce\n",
        "        # training or validation samples\n",
        "        path_A = self.base_path / \"trainA\" if self.train else self.base_path / \"testA\"\n",
        "        path_B = self.base_path / \"trainB\" if self.train else self.base_path / \"testB\"\n",
        "\n",
        "        for im_path in sorted((path_A).glob(\"*.jpg\")):\n",
        "            self.images.append((im_path, \"A\"))\n",
        "        for im_path in sorted((path_B).glob(\"*.jpg\")):\n",
        "            self.images.append((im_path, \"B\"))\n",
        "\n",
        "    def __len__(self):\n",
        "        # how many sample are available\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # what is \"sample\" i?\n",
        "        # it's a pair of an image tensor and its associated label.\n",
        "        # let's load the data and return a dictionnary structuring the sample\n",
        "        # (which could also be a tuple)\n",
        "\n",
        "        # find sample i\n",
        "        image_path, label_name = self.images[i]\n",
        "        # load image into a numpy array\n",
        "        image = io.imread(image_path)\n",
        "        # turn the label into an int\n",
        "        label = 0 if label_name == \"A\" else 1\n",
        "\n",
        "        # if a transformation has been provided, modify the\n",
        "        # loaded image accordingly.\n",
        "        # For instance: ToTensor() will turn the numpy array into a torch tensor\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return {\"input\": image, \"label\": label}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "256LSwbc1_6Q"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms as T\n",
        "\n",
        "# let's provide a sequence of transformations for the image numpy array:\n",
        "train_transforms = T.Compose(  # turn a list of functions into a chain\n",
        "    [\n",
        "        T.ToTensor(),  # turn the numpy array into a [0; 1] tensor with shape [3x256x256]\n",
        "        T.RandomResizedCrop( # https://pytorch.org/vision/main/auto_examples/plot_transforms.html#randomresizedcrop\n",
        "            size=64, scale=(0.5, 0.5)\n",
        "        ),  # randomly crop and resize the image into a 3x64x64 tensor\n",
        "        T.RandomHorizontalFlip(),  # randomly flip the image horizontally\n",
        "        T.Normalize(0.5, 0.5),  # normalize the image so it lands in the [-1; 1] range\n",
        "    ]\n",
        ")\n",
        "# validation transforms are slightly different: let's not randomly modify the input,\n",
        "# we just want to know how the model performs\n",
        "validation_transforms = T.Compose([T.ToTensor(), T.Resize(64), T.Normalize(0.5, 0.5)])\n",
        "\n",
        "\n",
        "train_set = ImageDataset(data_path, train=True, transform=train_transforms)\n",
        "val_set = ImageDataset(data_path, train=False, transform=validation_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOgZEnAp1_6Q"
      },
      "outputs": [],
      "source": [
        "# let's have a look at what the train transforms look like\n",
        "f, axs = plt.subplots(2, 5, sharey=True, figsize=(15, 6))\n",
        "\n",
        "for k, idx in enumerate([0, 1500]):\n",
        "    for p in range(5):\n",
        "        x = train_set[idx][\"input\"].permute(1, 2, 0).numpy()\n",
        "        axs[k][p].imshow((x + 1) / 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PjPj88pMziz"
      },
      "source": [
        "### 2.2 Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGloxYddM4Zv"
      },
      "source": [
        "As explained earlier, we can use the `torch.utils.data.DataLoader` class to delegate sample creation and batching to sub-processes in order to free the main process from this burden and make data available faster to the GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuJYA0ylNL93"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,  # what Dataset to use in order to produce individual samples\n",
        "    batch_size=batch_size,  # how many samples to batch together\n",
        "    shuffle=True,  # let's not have samples batched together in the same order at each epoch\n",
        "    num_workers=2,  # how many sub-processes to use in the background; in general set to number of cores in your CPU\n",
        "    worker_init_fn=seed_worker,  # seed the worker so its inner-random processes are reproducible\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=batch_size, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMdTQvdyhYgq"
      },
      "source": [
        "### 2.3 Saving and Restoring models\n",
        "\n",
        "If you are happy with your model, you will want to save it after it is trained for your actual purpose.\n",
        "\n",
        "If the training procedure stopped (you ran out of time on colab!), you'll want to resume training.\n",
        "\n",
        "In both (and more) cases, you'll need to save a \"checkpoint\" of your model during its training. Typically at the end of every epoch if its validation performance is better than the previous epoch's.\n",
        "\n",
        "Reference: https://pytorch.org/tutorials/beginner/saving_loading_models.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSZxXN2_iRYq"
      },
      "outputs": [],
      "source": [
        "x = torch.rand((3, 1))\n",
        "\n",
        "model_1 = LinearModel(1, 1)\n",
        "model_2 = LinearModel(1, 1)\n",
        "\n",
        "y_1 = model_1(x)\n",
        "y_2 = model_2(x)\n",
        "\n",
        "print(\"Different models will start off differently:\")\n",
        "print(y_1.detach().numpy())\n",
        "print(y_2.detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17msT9w8i5FX"
      },
      "outputs": [],
      "source": [
        "# save the model for future inference:\n",
        "\n",
        "torch.save(model_1, \"./model_1.pt\")\n",
        "resumed_1 = torch.load(\"./model_1.pt\")  # no need to know the base class of the model\n",
        "\n",
        "assert (resumed_1(x) == model_1(x)).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ifu3hYfjJf0"
      },
      "outputs": [],
      "source": [
        "# save the model, the optimizer and any other info using state_dicts\n",
        "\n",
        "torch.save(\n",
        "    {\n",
        "        \"model\": model_1.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"epoch\": e,\n",
        "        \"batch_size\": batch_size,\n",
        "    },\n",
        "    \"./state_dicts_1.pt\",\n",
        ")\n",
        "\n",
        "state_dicts = torch.load(\"./state_dicts_1.pt\")\n",
        "resumed_dict_1 = LinearModel(1, 1)\n",
        "resumed_dict_1.load_state_dict(\n",
        "    state_dicts[\"model\"]\n",
        ")  # requires the base class of the model\n",
        "\n",
        "assert (resumed_dict_1(x) == model_1(x)).all()\n",
        "\n",
        "# exactly the same goes for the optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM1FEBcCRnQB"
      },
      "source": [
        "## 3. Real-world training scenario in Computer Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6baeV3AiRsOA"
      },
      "source": [
        "Now that we know how to create a model and train it on some data we can efficiently load from files on disk, let's look at a real world scenario: \n",
        "\n",
        "Binary classification of summer/winter Yosemite pictures usinc Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Q0DRVV1_6Q"
      },
      "source": [
        "### 3.1 CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ3SRA201_6Q"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_channels,\n",
        "        output_channels,\n",
        "        kernel_size=3,\n",
        "        stride=2,\n",
        "        bn=True,\n",
        "        activation=nn.ReLU(),\n",
        "        dropout=0,\n",
        "    ):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                input_channels, output_channels, kernel_size=3, stride=2, bias=not bn\n",
        "            ),\n",
        "            activation,\n",
        "            nn.BatchNorm2d(output_channels) if bn else nn.Identity(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_channels=3,  # how many channels do inputs have?\n",
        "        conv_channels=[\n",
        "            32,\n",
        "            64,\n",
        "            128,\n",
        "        ],  # how many convolutional layers (and how many channels)?\n",
        "        strides=None,  # specify conv. layers' strides (None => automatically set to 1)\n",
        "        kernel_sizes=None,  # kernel sizes for each conv. layer (None => automatically set to 3)\n",
        "        batch_norm=True,  # whether or not to use BatchNorm\n",
        "        activation=nn.LeakyReLU(),  # what non-linearity to use?\n",
        "        mlp_layers=[\n",
        "            256,\n",
        "            64,\n",
        "            2,\n",
        "        ],  # how many (and how wide) fully-connected layers in the final predictor\n",
        "        dropout=0.4,  # probability of setting \"neurons\" to 0 at train-time\n",
        "        classes=2,  # how many classes for this task, i.e. the model's output layer size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # initialize kernel sizes and strides if not provided\n",
        "        if kernel_sizes is None:\n",
        "            kernel_sizes = [3] * len(conv_channels)\n",
        "        if strides is None:\n",
        "            strides = [1] * len(conv_channels)\n",
        "\n",
        "        # convolutional layers' number of channels\n",
        "        channels = [input_channels] + conv_channels\n",
        "\n",
        "        conv_layers = []\n",
        "\n",
        "        for i in range(len(channels) - 1):\n",
        "            input_c = channels[i]\n",
        "            output_c = channels[i + 1]\n",
        "            # create a convolutional layer\n",
        "            conv_layers.append(\n",
        "                ConvBlock(\n",
        "                    channels[i],\n",
        "                    channels[i + 1],\n",
        "                    kernel_sizes[i],\n",
        "                    strides[i],\n",
        "                    batch_norm,\n",
        "                    activation,\n",
        "                    dropout,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # turn the list into a torch.nn.Module that automatically\n",
        "        # chains .forward() calls\n",
        "        self.conv_layers = nn.Sequential(*conv_layers)\n",
        "\n",
        "        # average features across the spatial dimension.\n",
        "        # the output shape will be batch_size x conv_channels[-1] x 1 x 1\n",
        "        self.aggregation = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        mlp = []\n",
        "        mlp_sizes = [conv_channels[-1]] + mlp_layers\n",
        "        for i in range(len(mlp_sizes) - 1):\n",
        "            # create a linear layer\n",
        "            mlp.append(nn.Linear(mlp_sizes[i], mlp_sizes[i + 1]))\n",
        "            # add non-linearity\n",
        "            mlp.append(activation)\n",
        "            # add dropout\n",
        "            mlp.append(nn.Dropout(dropout))\n",
        "\n",
        "        # again, turn list into module\n",
        "        self.mlp = nn.Sequential(*mlp)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # how to process a sample through the model?\n",
        "\n",
        "        # compute the output feature maps after all convolutional layers\n",
        "        y = self.conv_layers(x)\n",
        "        # aggregate features into a vector\n",
        "        y = self.aggregation(y)\n",
        "        # reshape to batch_size x conv_channels[-1] for the mlp\n",
        "        y = y.view(y.size(0), -1)\n",
        "        # forward through the mlp\n",
        "        y = self.mlp(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32uzFWipPf-r"
      },
      "source": [
        "Let's inspect the model and look at the shapes of intermediate features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI4oilf-1_6R"
      },
      "outputs": [],
      "source": [
        "model = CNN()\n",
        "\n",
        "print(model)\n",
        "print(\"\\nShape of intermediate features through the network:\")\n",
        "dummy = torch.rand(7, 3, 64, 64)\n",
        "print(f\"Input: {tuple(dummy.shape)}\")\n",
        "for layer in model.conv_layers:\n",
        "    dummy = layer(dummy)\n",
        "    if isinstance(layer, nn.Conv2d):\n",
        "        print(f\"  ->  {layer} -> {tuple(dummy.shape)}\")\n",
        "dummy = model.aggregation(dummy)\n",
        "print(f\"  ->  {model.aggregation} -> {tuple(dummy.shape)}\")\n",
        "dummy = dummy.view(dummy.size(0), -1)\n",
        "print(f\"  ->  Reshape -> {tuple(dummy.shape)}\")\n",
        "for layer in model.mlp:\n",
        "    dummy = layer(dummy)\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        print(f\"  ->  {layer} -> {tuple(dummy.shape)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNVtpJJ4kopV"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model, input_size=(7, 3, 64, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsvfQh0MVAww"
      },
      "source": [
        "### 3.2 GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Z-FmttVDol"
      },
      "source": [
        "As explained earlier, one of the main reasons to use Pytorch (or Tensorflow etc.) instead of Numpy, is that you can do all the mathematical operations in your model on a GPU. \n",
        "\n",
        "Let's look at how to do this in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YdP9Ds8XfWX"
      },
      "outputs": [],
      "source": [
        "torch.tensor(1).device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hxkpa7L5Xyav"
      },
      "outputs": [],
      "source": [
        "# do you have a GPU?\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ObIyK4VYGQG"
      },
      "outputs": [],
      "source": [
        "# how to put tensors onto the GPU?\n",
        "if torch.cuda.is_available():\n",
        "    # creating a tensor directly on the device is the preferred and fastest way to do so\n",
        "    print(torch.tensor(1, device=\"cuda:0\"))\n",
        "    # alternatives:\n",
        "    print(torch.tensor(1).to(torch.device(\"cuda:0\")))\n",
        "    print(torch.tensor(1).to(\"cuda:0\"))\n",
        "    print(torch.tensor(1).cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0w6elD5YcZ4"
      },
      "outputs": [],
      "source": [
        "# be careful: two intereacting tensors should (most often) live on the same device!\n",
        "if torch.cuda.is_available():\n",
        "    torch.rand((10, 10), device=\"cpu\") * torch.tensor(2, device=\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FOfptNmZkOu"
      },
      "outputs": [],
      "source": [
        "# models should be on GPUs too!\n",
        "if torch.cuda.is_available():\n",
        "    model = LinearModel(1, 1).to(\"cuda:0\")\n",
        "    x = torch.rand((5, 1))\n",
        "    try:\n",
        "        model(x)\n",
        "    except RuntimeError as e:\n",
        "        print(\"Woops:\")\n",
        "        print(\"  -> \" + str(e))\n",
        "    # let's send the input to the GPU\n",
        "    model(x.to(\"cuda:0\"))\n",
        "    print(\"Ok on GPU!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ngTggDrg2RQ"
      },
      "outputs": [],
      "source": [
        "# bring a tensor back to the CPU before you turn them\n",
        "# into numpy arrays or native types\n",
        "if torch.cuda.is_available():\n",
        "    tensor = torch.rand((3, 3, 3), device=\"cuda:0\")\n",
        "    array = tensor.cpu().numpy()\n",
        "    mean = tensor.mean().cpu().item()\n",
        "    mean = tensor.cpu().mean().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8Mdvgs4ae2_"
      },
      "source": [
        "### 3.3 Let's train!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSl3VfZic4Ze"
      },
      "source": [
        "Before we get into the actual training, let's recall the training procedure pseudo code:\n",
        "\n",
        "```python\n",
        "# create the main objects of your training procedure:\n",
        "# loaders, model, loss function & optimizer\n",
        "train_loader, val_loader = my_loaders(**kwards)\n",
        "model = MyModel().to(device)\n",
        "optimizer = Optimizer()\n",
        "loss = LossFunction()\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "\n",
        "    for batch, target in train_loader:\n",
        "\n",
        "        # don't forget devices\n",
        "        x = batch.to(device)\n",
        "        y = target.to(device)\n",
        "        \n",
        "        # don't let gradients accumulate!\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward the input through your model\n",
        "        prediction = model(x)\n",
        "\n",
        "        # compute the error using your loss function\n",
        "        error = loss(prediction, y)\n",
        "        # perform backward pass to compute gradients\n",
        "        error.backward()\n",
        "\n",
        "    # evaluate your model after each epoch (or less often, your choice)\n",
        "    eval_metric = evaluation_procedure(model, val_loader)\n",
        "\n",
        "    # save model if it's the best one so far\n",
        "    if eval_metric > best_eval_metric:\n",
        "        # use state_dict to be able to continue training\n",
        "        save(model, optimizer, epoch, batch_size)\n",
        "        \n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVSa0CC_UskG"
      },
      "source": [
        "**Great!** We have a model and the know-how to train it on a GPU, let's goooo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZK4pPVt_1_6R"
      },
      "outputs": [],
      "source": [
        "# hyper parameters\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "lr = 0.01\n",
        "\n",
        "# create device based on GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# create CNN model\n",
        "model = CNN().to(device)\n",
        "\n",
        "# as before: create optimizer and loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# store train/val error & accuracy\n",
        "errors = {\n",
        "    \"train\": [],\n",
        "    \"val\": [],\n",
        "}\n",
        "\n",
        "accuracies = {\"train\": [], \"val\": []}\n",
        "\n",
        "# initialize loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=batch_size, shuffle=True, num_workers=4\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=batch_size, shuffle=False, num_workers=4\n",
        ")\n",
        "\n",
        "print(model)\n",
        "\n",
        "# custom object in order to monitor how much we use the GPU\n",
        "# you can have a look at it in 0. Imports and Utils\n",
        "monitor = GPUMonitor()\n",
        "monitor.start()\n",
        "\n",
        "# ---------------------------------------\n",
        "# --  Start of the training procedure  --\n",
        "# ---------------------------------------\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "    train_errors = []\n",
        "    train_correct = 0\n",
        "\n",
        "    # Dropout and BatchNorm behave differently if you are training or evaluating\n",
        "    # the model. Here we need them to be in training mode\n",
        "    # (for instance, no dropout in evaluation mode)\n",
        "    model.train()\n",
        "\n",
        "    # ignore: clear print line\n",
        "    print(\" \" * 100, end=\"\")\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        print(f\"\\rEpoch {e+1}/{epochs} | Train Batch {i+1}/{len(train_loader)}\", end=\"\")\n",
        "\n",
        "        # clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # send tensors to the propper device\n",
        "        x = batch[\"input\"].to(device)\n",
        "        y = batch[\"label\"].to(device)\n",
        "\n",
        "        # forward through model\n",
        "        prediction = model(x)\n",
        "        # compute prediction error\n",
        "        error = loss(prediction, y)\n",
        "        # update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # store batch error\n",
        "        train_errors.append(error.cpu().item())\n",
        "        # store batch correct count (see 0. ) to compute accuracy\n",
        "        # on the full training set for this epoch\n",
        "        train_correct += correct(prediction, batch[\"label\"])\n",
        "\n",
        "    # clear print line\n",
        "    print(\" \" * 100, end=\"\")\n",
        "\n",
        "    # evaluation: no gradients needed\n",
        "    with torch.no_grad():\n",
        "        val_errors = []\n",
        "        val_correct = 0\n",
        "\n",
        "        # Put the model in evaluation mode (vs .train() mode)\n",
        "        model.eval()\n",
        "\n",
        "        for i, batch in enumerate(val_loader):\n",
        "            print(\n",
        "                f\"\\rEpoch {e+1}/{epochs} | Validation Batch {i+1}/{len(val_loader)}\",\n",
        "                end=\"\",\n",
        "            )\n",
        "            prediction = model(batch[\"input\"].to(device))\n",
        "            error = loss(prediction, batch[\"label\"].to(device))\n",
        "            val_errors.append(error.cpu().item())\n",
        "            val_correct += correct(prediction, batch[\"label\"])\n",
        "\n",
        "    # compute average errors\n",
        "    train_error = np.mean(train_errors)\n",
        "    val_error = np.mean(val_errors)\n",
        "\n",
        "    # compute epoch-wise accuracies\n",
        "    train_acc = train_correct / len(train_set) * 100\n",
        "    val_acc = val_correct / len(val_set) * 100\n",
        "\n",
        "    # store metrics\n",
        "    accuracies[\"train\"].append(train_acc)\n",
        "    accuracies[\"val\"].append(val_acc)\n",
        "    errors[\"train\"].append(train_error)\n",
        "    errors[\"val\"].append(val_error)\n",
        "\n",
        "    print(\n",
        "        f\"\\rEpoch {e+1}/{epochs} - Train error: {train_error:.4f} Train acc: {train_acc:.1f}% - Val error: {val_error:.4f} Val acc: {val_acc:.1f}%\"\n",
        "    )\n",
        "\n",
        "    # -------------------\n",
        "    # --  End of epoch --\n",
        "    # -------------------\n",
        "\n",
        "# -------------------------------------\n",
        "# --  End of the training procedure  --\n",
        "# -------------------------------------\n",
        "\n",
        "# stop the GPU monitor\n",
        "monitor.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQLgNODtuPlh"
      },
      "source": [
        "**Questions**:\n",
        "\n",
        "* Is this performance satisfactory? \n",
        "* Is tis task hard?\n",
        "  * Can you do it?\n",
        "  * Have you looked at the data enough?\n",
        "* What are the accuracy values for a random (*i.e.* non-trained) model?\n",
        "  * A model that always produces 0s?\n",
        "  * A model that randomly produces 0s or 1s?\n",
        "  * You should know the performace of some dummy baselines to grasp the range of \"minimally-acceptable values\" if you can\n",
        "* Is something wrong with your training procedure ?\n",
        "* Is something wrong with your model?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26Q3yF025cW0"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax1.plot(range(e), errors[\"train\"], label=\"Train\")\n",
        "ax1.plot(range(e), errors[\"val\"], label=\"Val\")\n",
        "ax1.title.set_text(\"Cross-Entropy Error\")\n",
        "ax2.plot(range(e), accuracies[\"train\"], label=\"Train\")\n",
        "ax2.plot(range(e), accuracies[\"val\"], label=\"Val\")\n",
        "ax2.title.set_text(\"Accuracy (%)\")\n",
        "\n",
        "monitor.plot_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg65VYOWey8p"
      },
      "source": [
        "## 4. Your turn to play around and improve accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nslK77jGfsse"
      },
      "source": [
        "The `train(...)` function below is just a functional copy of the cell above. Use it to play around with a custom model, data transforms and hyper parameters in order to improve final validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVStSwKS1_6R"
      },
      "outputs": [],
      "source": [
        "def train(train_set, val_set, model, batch_size, epochs, learning_rate):\n",
        "    # create device based on GPU availability\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # send model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # as before: create optimizer and loss\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # store train/val error & accuracy\n",
        "    errors = {\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    }\n",
        "\n",
        "    accuracies = {\"train\": [], \"val\": []}\n",
        "\n",
        "    # initialize loaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=batch_size, shuffle=True, num_workers=2\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_set, batch_size=batch_size, shuffle=False, num_workers=2\n",
        "    )\n",
        "\n",
        "    print(model)\n",
        "\n",
        "    # custom object in order to monitor how much we use the GPU\n",
        "    # you can have a look at it in 0. Imports and Utils\n",
        "    monitor = GPUMonitor()\n",
        "    monitor.start()\n",
        "\n",
        "    #\n",
        "    # Start of the training procedure\n",
        "    #\n",
        "\n",
        "    for e in range(epochs):\n",
        "\n",
        "        train_errors = []\n",
        "        train_correct = 0\n",
        "\n",
        "        # Dropout and BatchNorm behave differently if you are training or evaluating\n",
        "        # the model. Here we need them to be in training mode\n",
        "        # (for instance, no dropout in evaluation mode)\n",
        "        model.train()\n",
        "\n",
        "        # ignore: clear print line\n",
        "        print(\" \" * 100, end=\"\")\n",
        "\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            print(\n",
        "                f\"\\rEpoch {e+1}/{epochs} | Train Batch {i+1}/{len(train_loader)}\",\n",
        "                end=\"\",\n",
        "            )\n",
        "\n",
        "            # clear gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # send tensors to the propper device\n",
        "            x = batch[\"input\"].to(device)\n",
        "            y = batch[\"label\"].to(device)\n",
        "\n",
        "            # forward through model\n",
        "            prediction = model(x)\n",
        "            # compute prediction error\n",
        "            error = loss(prediction, y)\n",
        "            # perform backward pass\n",
        "            error.backward()\n",
        "            # update model parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # store batch error\n",
        "            train_errors.append(error.cpu().item())\n",
        "            # store batch correct count (see 0. ) to compute accuracy\n",
        "            # on the full training set for this epoch\n",
        "            train_correct += correct(prediction, batch[\"label\"])\n",
        "\n",
        "        # clear print line\n",
        "        print(\" \" * 100, end=\"\")\n",
        "\n",
        "        # evaluation: no gradients needed\n",
        "        with torch.no_grad():\n",
        "            val_errors = []\n",
        "            val_correct = 0\n",
        "\n",
        "            # Put the model in evaluation mode (vs .train() mode)\n",
        "            model.eval()\n",
        "\n",
        "            for i, batch in enumerate(val_loader):\n",
        "                print(\n",
        "                    f\"\\rEpoch {e+1}/{epochs} | Validation Batch {i+1}/{len(val_loader)}\",\n",
        "                    end=\"\",\n",
        "                )\n",
        "                prediction = model(batch[\"input\"].to(device))\n",
        "                error = loss(prediction, batch[\"label\"].to(device))\n",
        "                val_errors.append(error.cpu().item())\n",
        "                val_correct += correct(prediction, batch[\"label\"])\n",
        "\n",
        "        # compute average errors\n",
        "        train_error = np.mean(train_errors)\n",
        "        val_error = np.mean(val_errors)\n",
        "\n",
        "        # compute epoch-wise accuracies\n",
        "        train_acc = train_correct / len(train_set) * 100\n",
        "        val_acc = val_correct / len(val_set) * 100\n",
        "\n",
        "        # store metrics\n",
        "        accuracies[\"train\"].append(train_acc)\n",
        "        accuracies[\"val\"].append(val_acc)\n",
        "        errors[\"train\"].append(train_error)\n",
        "        errors[\"val\"].append(val_error)\n",
        "\n",
        "        print(\n",
        "            f\"\\rEpoch {e+1}/{epochs} - Train error: {train_error:.4f} Train acc: {train_acc:.1f}% - Val error: {val_error:.4f} Val acc: {val_acc:.1f}%\"\n",
        "        )\n",
        "\n",
        "        # --------------------\n",
        "        # --  End of epoch  --\n",
        "        # --------------------\n",
        "\n",
        "    # -------------------------------------\n",
        "    # --  End of the training procedure  --\n",
        "    # -------------------------------------\n",
        "\n",
        "    # stop the GPU monitor\n",
        "    monitor.stop()\n",
        "\n",
        "    # return metric\n",
        "    return errors, accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AXO_eN-gCfF"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms as T\n",
        "\n",
        "# Feel free to customize training transforms!\n",
        "# For the sake of the exercise, keep sizes to 64\n",
        "train_transforms = T.Compose(\n",
        "    [\n",
        "        T.ToTensor(),  # keep this first\n",
        "        T.RandomResizedCrop(size=64, scale=(0.8, 1)),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.Normalize(0.5, 0.5),  # keep this last\n",
        "    ]\n",
        ")\n",
        "\n",
        "# keep `validation_transforms` as is\n",
        "validation_transforms = T.Compose([T.ToTensor(), T.Resize(64), T.Normalize(0.5, 0.5)])\n",
        "\n",
        "\n",
        "train_set = ImageDataset(data_path, train=True, transform=train_transforms)\n",
        "val_set = ImageDataset(data_path, train=False, transform=validation_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEfR5xXn1_6S"
      },
      "outputs": [],
      "source": [
        "class YourModel(nn.Module):\n",
        "    def __init__(self, some_args):\n",
        "        super().__init__()\n",
        "        # up to you!\n",
        "\n",
        "    def forward(self, x):\n",
        "        # what do you want to do with this batch of inputs?\n",
        "        y = x\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62cnn7s81_6S"
      },
      "outputs": [],
      "source": [
        "e, a = train(\n",
        "    train_set=train_set,\n",
        "    val_set=val_set,\n",
        "    model=CNN(),\n",
        "    batch_size=128,\n",
        "    epochs=10,\n",
        "    learning_rate=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrOMXNuN1_6S"
      },
      "outputs": [],
      "source": [
        "# see 0. to see the code for this, but you can just use it as is\n",
        "# if you use the output of train()\n",
        "plot_error_and_accuracy(e, a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otKKw5mhk6tW"
      },
      "source": [
        "After you have experimented with different models, layers, optimizers, schedulers etc. an idea could be to look into transfer learning: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFNOyVQ_lImY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIZDIpQLiROm"
      },
      "source": [
        "## Further readings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_KmhvhyvTLN"
      },
      "source": [
        "\n",
        "* More autograd: maths & computational graphs https://pytorch.org/blog/overview-of-pytorch-autograd-engine\n",
        "* Official autograd tutorial with examples https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n",
        "* A great collection of tutorials per application: CV, NLP, RL, Speech etc. https://pytorch.org/tutorials/\n",
        "* Be curious: learn from the questions and answers on StackOverflow https://stackoverflow.com/questions/tagged/pytorch, typically:\n",
        "  * [What's the difference between reshape and view in pytorch?](https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch)\n",
        "  * [PyTorch - What does contiguous() do?](https://stackoverflow.com/questions/48915810/pytorch-what-does-contiguous-do)\n",
        "  * [Understanding torch.nn.Parameter](https://stackoverflow.com/questions/50935345/understanding-torch-nn-parameter)\n",
        "* A major NLP/Transformers library https://huggingface.co/docs/transformers/index\n",
        "* A list of great things https://github.com/bharathgs/Awesome-pytorch-list\n",
        "    * \n",
        "* GPU-accelerated and differentiable computer vision operations https://github.com/kornia/kornia\n",
        "* Model summaries https://github.com/TylerYep/torchinfo\n",
        "* Online logging and experiment tracking https://www.comet.ml/\n",
        "* Same ^ https://wandb.ai/\n",
        "* Make your work reproducible https://pytorch.org/docs/stable/notes/randomness.html\n",
        "* More on reproducibility (get used to this forum!) https://discuss.pytorch.org/t/reproducibility-with-all-the-bells-and-whistles/81097\n",
        "* Multi-node training intro https://pytorch.org/tutorials/beginner/dist_overview.html\n",
        "* Faster Pytorch coding: a framework built on top of it https://pytorchlightning.ai/\n",
        "* An unofficial styleguide and best practices summary for PyTorch https://github.com/IgorSusmelj/pytorch-styleguide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asJDS2P79qDK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWZlT26Mruuk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tutorial2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}